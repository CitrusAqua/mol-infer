\documentclass[11pt, titlepage, dvipdfmx, twoside]{jarticle}
\linespread{1.1}
%\documentclass[11pt,dvipdfmx,twoside]{jarticle}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% style definitions
%
% following setting makes 3cm spaces for top and bottom, and
% 2.5cm spaces for left and right
%
                                         % default setting
\setlength{\oddsidemargin}{22pt}         % 62pt
\setlength{\evensidemargin}{22pt}        % 62pt
\setlength{\headheight}{12pt}            % 12pt
\setlength{\textheight}{662pt}           % 592pt
\setlength{\marginparsep}{10pt}          % 10pt
\setlength{\footskip}{30pt}              % 30pt
\setlength{\hoffset}{-13pt}              % 0pt
\setlength{\paperwidth}{597pt}           % 597pt
\setlength{\topmargin}{20pt}             % 20pt
\setlength{\headsep}{25pt}               % 25pt
\setlength{\textwidth}{427pt}            % 327pt
\setlength{\marginparwidth}{106pt}       % 106pt
\setlength{\marginparpush}{5pt}          % 5pt
\setlength{\voffset}{-37pt}              % 0pt
\setlength{\paperheight}{845pt}          % 845pt


% 1 inch = 2.54 cm = 72.27 pt

\renewcommand{\baselinestretch}{1.20}
\long\def\invis#1{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[dvipdfmx]{graphicx}
\usepackage{framed}
\usepackage{url}
\usepackage{color}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\project}{{\tt mol-infer/2L-model}}
%\newcommand{\project}{{\tt mol-infer/Cyclic}}
\newcommand{\secref}[1]{第\ref{sec:#1}節}
\newcommand{\tabref}[1]{表\ref{tab:#1}}
\newcommand{\figref}[1]{図\ref{fig:#1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{\huge Module 2におけるニューラルネットワーク学習の手順}
\author{\project}
\begin{document}
\makeatletter 
\let\c@lstlisting\c@figure
\makeatother
\西暦
\date{\today}
\maketitle
\thispagestyle{empty}
\tableofcontents
\clearpage
\pagenumbering{arabic}


\section{はじめに}
本稿では，本プロジェクト (\project) における Module 2の手順を解説する．

与えられた化学グラフの集合を $D_\pi=\{G_1,G_2,\dots,G_p\}$,
化学グラフを特徴ベクトルに変換する写像を $f$ とする.
${\mathcal F}(D_\pi)\triangleq\{f(G_1),f(G_2),\dots,f(G_p)\}$と定義する
(すなわち ${\mathcal F}(D_\pi)$は特徴ベクトルの集合). 
また, 注目する化学的性質を $\pi$ と書くことにする.
この $\pi$ は，たとえば水可溶性，脂溶性，沸点，燃焼熱，水分配係数など様々である．
Module 2 の入力と出力は以下の通りである．

\begin{oframed}
\begin{description}
\item[入力:] 特徴ベクトルの集合 ${\mathcal F}(D_\pi)=\{x_1,x_2,\dots,x_p\}$，
  各化合物 $G_i\in D_\pi$ もといその特徴ベクトル $x_i=f(G_i)\in{\mathcal F}(D_\pi)$
  が化学的性質 $\pi$ に関して持つ値の集合 $\{a(x_1),a(x_2),\dots,a(x_p)\}$，
  ニューラルネットワークの各種パラメータの値（隠れ素子の個数など）．
\item[出力:] 入力で指定された構造を持ち，${\mathcal F}(D_\pi)$における
  「多くの」特徴ベクトル $x\in {\mathcal F}(D_\pi)$に
  対して
  化学的性質の値 $a(x)$ を「良く」推定するようなニューラルネットワーク．
\end{description}
\end{oframed}
出力の具体的な中身は，学習されたニューラルネットワークにおける
各枝の重みと各ノードのバイアスである．

本稿の構成は以下の通りである．
\begin{itemize}
\item \secref{preparation}: 基本的な用語，およびパッケージのファイル構成の説明．
\item \secref{quick}: 簡単な実行例．
\item \secref{io}: プログラムの入出力に関する詳細．
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{準備}
\label{sec:preparation}

\subsection{用語の説明}
\paragraph{特徴ベクトル．}
各元素の種類の原子数等の化学物質を説明する数値，
あるいはグラフの直径等の化学物質のグラフ表現のトポロジーに基づいて
計算される数値のベクトル．

\paragraph{人工ニューラルネットワーク (ANN)．}
人工ニューラルネットワーク (artifician neural network, ANN)，
または単にニューラルネットワーク (NN) とは，機械学習で最も確立した手法の1つである．これらは入力ベクトルに基づいて値を予測するために用いられる．この冊子では，ニューラルネットワークへの入力は，化合物の特徴ベクトルであり，出力は特定の化学的性質の予測値である．

本プロジェクトで用いるのはフィードフォーワード型のニューラルネットワークであり，
これは非巡回有向グラフによって表すことができる．\figref{sample}に例を示す．

\begin{figure}[h!]
  \centering
  \includegraphics[width = 0.4 \textwidth]{./fig/ANN_sample_jp}
  \caption{ニューラルネットワークの具体例．
  赤色の数値が重み，青色の数値がバイアスを表している．枝はすべて左から右に向いている．}
  \label{fig:sample}
\end{figure}

\paragraph{入力層，隠れ層，出力層．}
人工ニューラルネットワークの多層パーセプトロンモデルを仮定する．このモデルでは，ニューラルネットワークはいくつかの層で構成されている．最初の層は入力層で，入力層は場合によっては特徴ベクトルから数値データを得るため，特徴ベクトルの要素と同じ数のノードがある．次に数値は隠れ層を介して伝播される．隠れ層は1つの層の計算が次の層への入力として用いられる．最後に出力層が入力ベクトルに基づいた予測値を与える．

\figref{sample}では，入力層は3つのノードを持つ．
したがって入力する特徴ベクトルは3次元のものでなければならない．
また1つの隠れ層を有し，この隠れ層は2つのノードを持つ．
そして出力層は1つのノードを持つ．

\paragraph{重み．}
ニューラルネットワークでは，ノード間を接続する枝（有向枝）にはそれぞれ数値が割り当てられ，
その値を重みと呼ぶ．入力層から出力層への値の伝播には，これらの重みに基づく計算が含まれている．

\figref{sample}では，枝の重みは赤によって示される．


\paragraph{バイアス．}
ニューラルネットワークの隠れ層の各ノードにはバイアスと呼ばれる数値が割り当てられている．この数値は重みと共に，入力ベクトルに基づいて出力値を計算する過程で使用される．

\figref{sample}では，ノードのバイアスは青によって示される．

\paragraph{活性化関数．}
活性化関数はニューラルネットワークの各ノードに割り当てられており，
与えられた入力ベクトルから出力値を計算する際に用いられる．
特に各ノードの出力値は，重み付けされた対応する枝の重みと
前の層からのノードの出力の線形結合を入力として与えられた活性化関数の値である．

本プロジェクトでは，{\bf 隱れ層の各ノードの活性化関数として
Rectified Linear-Unit (ReLU) 関数に限定}して用いる．
これは次の Module 3 (この Module 2 で学習したニューラルネットワークに基づいた化合物推定)
では，活性化関数が ReLU であることを仮定しているからである． 

\medskip

%ニューラルネットワークは，与えられた入力ベクトルと目標値の組に基づいて
%重みとバイアスの組を計算する．このプロセスは一般に「学習」と呼ばれる．


\subsection{ファイル構成}
パッケージに含まれるファイルとその役割は\tabref{files}の通りである．
\begin{table}[h!]
  \centering
  \caption{Module 2 のパッケージに含まれるファイルとその役割}
  \label{tab:files}
  \begin{tabular}{lcll}
  \hline
  \bf ファイル名 &\ \ & \multicolumn{2}{l}{\bf 役割}\\
  \hline
  \verb|2L_ANN.py| && \multicolumn{2}{l}{NNを学習するためのPythonスクリプト}\\
  &&\multicolumn{2}{l}{\bf （Module 3に進むにはこのスクリプトの実行が必要）}\\
  &&\multicolumn{2}{l}{$\bullet$使用する非標準ライブラリ: {\tt numpy, pandas, scikit-learn}}\\
  \hline
  %\verb|predict_values.py| && \multicolumn{2}{l}{学習したNNを用いて}\\
  %&&\multicolumn{2}{l}{化学的性質の値を推定するための補助的なPythonスクリプト}\\
  %&&\multicolumn{2}{l}{（このスクリプトの実行は必ずしも必要ではない）}\\
  %&&\multicolumn{2}{l}{$\bullet$使用する非標準ライブラリ: {\tt numpy, pandas}}\\
  %\hline
  \multicolumn{4}{l}{\tt Manual\_Module\_2\_2L-model\_jp.pdf}\\
  \multicolumn{4}{l}{\tt Manual\_Module\_2\_2L-model\_jp.tex}\\
  \multicolumn{4}{l}{\tt fig/ANN\_sample\_jp.eps}\\
  &&\multicolumn{2}{l}{マニュアルのPDF，\LaTeX ソースファイル}\\
  &&\multicolumn{2}{l}{および画像ファイル（日本語版）}\\
  \hline
  \multicolumn{4}{l}{\tt Manual\_Module\_2\_2L-model\_en.pdf}\\
  \multicolumn{4}{l}{\tt Manual\_Module\_2\_2L-model\_en.tex}\\
  \multicolumn{4}{l}{\tt fig/ANN\_sample\_en.eps}\\
  &&\multicolumn{2}{l}{マニュアルのPDF，\LaTeX ソースファイル}\\
  &&\multicolumn{2}{l}{および画像ファイル（英語版）}\\
  \hline
  \multicolumn{4}{l}{{\bf サンプルデータ} (水可溶性 ESOL に関するデータ; \url{http://moleculenet.ai/datasets-1})}\\
  \multicolumn{2}{l}{\tt data/Sl\_all\_eli.sdf} & \multicolumn{2}{l}{元となるSDFファイル. 本モジュールでは取扱わない.}\\
  \multicolumn{4}{l}{{\tt data/Sl\_all\_eli\_desc\_norm.csv}$^{\ast}$} \\
  &&\multicolumn{2}{l}{{\tt Sl\_all\_eli.sdf}にModule 1の特徴ベクトル生成器を}\\
  &&\multicolumn{2}{l}{適用して得られたcsvファイル. ${\mathcal F}(D_\pi)$に相当.}\\
  \multicolumn{2}{l}{{\tt data/Sl\_values.txt}$^{\ast\ast}$} & \multicolumn{2}{l}{水可溶性に関する観測値が書かれたテキストファイル.}\\
  &&\multicolumn{2}{l}{$\{a(x_1),\dots,a(x_p)\}$に相当.}\\
  \multicolumn{4}{l}{\tt data/Sl\_all\_eli\_biases.txt} \\
  \multicolumn{4}{l}{\tt data/Sl\_all\_eli\_weights.txt}\\
  &&\multicolumn{2}{l}{$\ast$および$\ast\ast$に対し, 本モジュールの学習スクリプト}\\
  &&\multicolumn{2}{l}{{\tt 2L\_ANN.py}を適用して得られたNNに関するデータファイル.}\\
  &&\multicolumn{2}{l}{前者がノードバイアス, 後者が枝重みに関するファイルで,}\\
  &&\multicolumn{2}{l}{\bf この二つは次の Module 3 の実行に必要である.}\\
  \hline
  \end{tabular}
\end{table}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{クイックスタート}
\label{sec:quick}

%\paragraph{ニューラルネットワークの学習．}

次のコマンドを入力すれば，
\verb|data/Sl_all_eli_desc_norm.csv|を特徴ベクトル，
\verb|data/Sl_values.txt|を観測値とするようなデータセットに対し，
2つの隠れ層を持ち，それぞれの隠れ層における
ノード数を20, 10とするようなニューラルネットワークが,
乱数の種を変えていくつか学習される.
なお一つのニューラルネットワークを学習するための
アルゴリズム (Adam法) の反復回数は10,000である.
学習されたニューラルネットワークのうち一つが
ある基準にしたがって選択される. 
選択されたニューラルネットワークにおける各ノードのバイアスは
\verb|output_biases.txt|，
各枝の重みは\verb|output_weights.txt|
にそれぞれ出力される．

\begin{oframed}
{\small
\begin{verbatim}
$ python 2L_ANN.py data/Sl_all_eli_desc_norm.csv data/Sl_values.txt\
                   output 10000 20 10
\end{verbatim}
}
\end{oframed}

出力されたニューラルネットワークの{\bf 重みおよびバイアスに関するファイルは，Module 3でも使用}する．

\invis{
\paragraph{化学的性質の値の推定．}
学習したニューラルネットワークを用いて，
化合物の化学的性質の値を推定することができる．

次のコマンド\footnote{一行目の最後のバックスラッシュ $\backslash$ は，実際に入力するときには改行してはならないことを示す．}を入力すれば，
学習済ニューラルネットワーク（枝の重みは\verb|output_weights.txt|，ノードのバイアスは\verb|output_biases.txt|に保持されている）を用いて，\verb|data/BP_fv.csv|に記述された特徴ベクトル（に対応する化合物）の化学的性質の値が推定され，その結果は\verb|predicted.txt|に出力される．

\begin{oframed}
  {\small
\begin{verbatim}
$ python predict_values.py output_weights.txt output_biases.txt \
    data/BP_fv.csv predicted.txt
\end{verbatim}
}
  \end{oframed}

\begin{itemize}
\item 化学的性質の値を推定したい化合物の特徴ベクトルは，Module 1の特徴ベクトル生成器を用いて生成することができる．
\item 上のコマンドは，さらに上のコマンド$(\clubsuit)$で\verb|data/BP_fv.csv|を
  特徴ベクトルとしたデータセットから学習したニューラルネットワークに関する \verb|output_weights.txt|および \verb|output_biases.txt|を用いるものとみなせば，
  データセット自身の化学的性質の値を推定していることになる．
\item この推定機能は補助的なものに過ぎず，Module 3以降で使用することはない．
\end{itemize}
}

\section{プログラムの入出力に関する詳細}
\label{sec:io}

\subsection{入力}
\subsubsection{特徴ベクトル}
特徴ベクトルは，我々が{\bf FV形式}と呼ぶフォーマットに基づく
csvファイルに記述されている必要がある．
Module 1の特徴ベクトル生成器は
化合物に関するSDFファイルから
FV形式のcsvファイルを生成するため，
当該生成器を用いて生成されたファイルを用いれば問題はない．

以下，FV形式の記述ルールを簡単に記しておく．
\begin{oframed}
  {\small
\begin{verbatim}
CID,n,cs,ch,nsH
244,8,6,2,8
307,10,6,4,8
657014,11,7,1,18
16704,9,9,0,10
\end{verbatim}
}
\end{oframed}
\begin{itemize}
\item FV形式では先頭行に記述子の名前をコンマ区切りで記述する．
\item ただし最初の記述子は CID（化合物識別番号）でなければならない．CIDの値が学習に用いられることはない．CIDは識別のためのみに用いられる．
\item 上記の例では，\verb|n|（水素を除く原子の個数），\verb|cs|（コアサイズ），\verb|ch|（コアハイト），\verb|nsH|（水素原子の個数）と四つの記述子が定められている．
\item 二行目以降に，一つの行に一つの化合物のCIDおよび特徴ベクトルを，コンマ区切りで記述する．
  したがって各化合物は，4次元の特徴ベクトルで表されることになる．
\item 化合物の順序は任意である. %CIDの昇順あるいは降順に並んでいる必要はない．
\end{itemize}


\subsubsection{化学的性質の値}
化学的性質の値は，CIDと値を羅列したcsvファイルに記述されなければならない．
\begin{oframed}
  {\small
\begin{verbatim}
CID,a
307,11.2
244,-0.5
657014,98.124
16704,-12.8
117,5.3
\end{verbatim}
}
\end{oframed}
\begin{itemize}
\item {\bf 先頭行は\verb|CID,a|でなければならない．}
\item 二行目以降に，一つの行に一つの化合物のCIDおよび化学的性質の値を
  コンマ区切りで記述する．
\item 化合物の順序は任意である. %CIDの昇順あるいは降順に並んでいる必要はない．
\end{itemize}
  
\subsection{実行}
\secref{quick}で示したとおり，
ニューラルネットワークを学習するには{\tt 2L\_ANN.py}を用いる．

\subsubsection{引数}
\secref{quick}で示したコマンドを再掲する．
\begin{oframed}
{\small
\begin{verbatim}
$ python 2L_ANN.py data/Sl_all_eli_desc_norm.csv data/Sl_values.txt\
                   output 10000 20 10
\end{verbatim}
}
\end{oframed}

各引数には以下を指定する．カッコ内の値は, 上記の例において指定されている値を示す. 
\begin{itemize}
\item 第1引数: 特徴ベクトルに関するcsvファイルの名前 (\verb|data/Sl_all_eli_desc_norm.csv|). 
\item 第2引数: 化学的性質の値に関するcsvファイルの名前 (\verb|data/Sl_values.txt|). 
\item 第3引数: ニューラルネットワークの重み・バイアスを書き込むファイルステムの文字列 (\verb|output|).
\item 第4引数: 学習アルゴリズムにおける反復回数 (\verb|10000|).
\item 第5引数以降: 隠れ層（中間層）のノードの個数  (\verb|20 10|).
\end{itemize}

引数を与えずに実行すれば（もしくは引数が適切に与えられなかった場合），
引数に関する説明が英語で出力される．
\begin{oframed}
  {\small
\begin{verbatim}
$ python 2L_ANN.py 
\end{verbatim}
  }
  \end{oframed}


引数が適切に与えられると，ニューラルネットワークの学習が始まる．
いくつかの乱数の種に対して5分割交差検定が行われ, 
最も高い決定係数 (${\rm R}^2$ 値) を達成した交差検定において,
五回の学習のうち試験集合に対して最も高い決定係数を
実現するニューラルネットワークが採用され，
その重みとバイアスが，ファイルに出力される．
上記のコマンドの場合，そのファイルの名前は第3引数で指定された\verb|output|に基づく，
\begin{itemize}
\item \verb|output_weights.txt|（重み）
\item \verb|output_biases.txt|（バイアス）
\end{itemize}
である．これら出力されたファイルは，Module 3 の実行に必要となる．


\paragraph{データセットに関する注意．}
データセットは，
\begin{itemize}
\item 特徴ベクトルに関するcsvファイル，および
\item 化学的性質の値に関するcsvファイル
\end{itemize}
の二つのファイルから構成されるが，
CID は前者ファイルに記されたものすべて，かつそれのみが計算の対象となる．
したがって，
\begin{center}
  {\bf 前者ファイルに記されたCIDは，
  すべて後者ファイルに記されていなければならない．}
\end{center}
しかし逆は成り立たなくともよい．
つまり，化学的性質の値に関するcsvファイルには，
特徴ベクトルのcsvファイルに記されていない，
「余計な」CIDに関する値が記されていても構わない．
そのような値は無視される．

\subsubsection{ハイパーパラメータの調整}
ニューラルネットワークの学習は{\tt scikit-learn}ライブラリ\footnote{\url{https://scikit-learn.org/stable/}}
における{\tt MLPRegressor}を用いて行われる．
\verb|2L_ANN.py|の125行目以降で\verb|MLPRegressor|インスタンスの初期化が行われるが，
ハイパーパラメータの調整はここで行うことができる．
一部のパラメータを以下のように設定している．
\begin{itemize}
\item \verb|activation|: \verb|'relu'| {\color{red}{\bf 注意:} 学習されたニューラルネットワークを Module 3 以降で用いるには, \verb|'relu'| (ReLU関数) でなければならない．}
\item \verb|alpha|: $10^{-5}$
\item \verb|early_stopping|: \verb|False|
\item \verb|hidden_layer_sizes|: 実行時に引数で指定した個数に基づく
\item \verb|max_iter|: $10^{10}$
\item \verb|random_state|: 変数\verb|ANN_seed|の値. この変数の値として, タプル\verb|ANN_SEED| (26行目) に格納したすべての値が試される. 
\item \verb|solver|: \verb|'adam'|
\end{itemize}

また交差検定の乱数の種は135行目で指定される ({\tt KFold}インスタンスの初期化における{\tt random\_state}の値).
この乱数の種として, タプル\verb|SPLIT_SEED| (27行目) に格納したすべての値が試される. 


\subsection{出力}
ふたたび以下のコマンドを取り上げ，
その実行によって得られる出力について説明する．
\begin{oframed}
{\small
\begin{verbatim}
$ python 2L_ANN.py data/Sl_all_eli_desc_norm.csv data/Sl_values.txt\
                   output 10000 20 10
\end{verbatim}
}
\end{oframed}


\subsubsection{標準出力}
上記コマンドを実行すると端末（標準出力）に計算過程が出力される．
\begin{oframed}
  {\small
\begin{verbatim}
### (ANN_seed, split_seed)=(1,1), fold=1/5 ###
# t	train	test	time
100	0.8486	0.8183	0.2774
200	0.9570	0.8509	0.8056
300	0.9757	0.8321	1.5904
400	0.9798	0.8231	2.0535
500	0.9766	0.8232	2.0819
600	0.9793	0.8232	2.1133
700	0.9775	0.8230	2.1433
800	0.9782	0.8233	2.1737
900	0.9777	0.8229	2.2041
1000	0.9775	0.8231	2.2346
2000	0.9777	0.8230	2.2629
3000	0.9775	0.8233	2.2916
4000	0.9775	0.8233	2.3210
5000	0.9774	0.8233	2.3511
6000	0.9774	0.8225	2.3810
7000	0.9774	0.8236	2.4108
8000	0.9774	0.8225	2.4409
9000	0.9771	0.8228	2.4729
10000	0.9771	0.8225	2.5017


### (ANN_seed, split_seed)=(1,1), fold=2/5 ###
# t	train	test	time
100	0.8564	0.7537	0.2840
200	0.9648	0.8513	0.8229

(途中略)

========== COMPLETE ==========

Best R^2 value among all cross-validations:	0.859528

The performance of the selected neural network:
	R^2 value for training set:	0.962288
	R^2 value for test set:	0.884223

The data for the selected neural network is stored in
output_biases.txt and output_weights.txt.
They are required in Module 3.
\end{verbatim}        
}
\end{oframed}

\begin{itemize}
\item 先に述べたとおり, \verb|2L_ANN.py|ではいくつかの乱数の種について
5分割交差検定が行われる. 
乱数の種とは学習アルゴリズムに関するものと交差検定の分割に関するものの二種類である. 
前者は\verb|ANN_SEED| (26行目) で定め,
後者は\verb|SPLIT_SEED| (27行目) で定める. 
前者と後者に貯えられた値のすべての組について5分割交差検定が行われる. 
デフォルトでは前者に二つ, 後者に一つの値が入っていることから, 
$2\times 1=2$ 回の交差検定が行われる. 
さらに一回の交差検定では五回の学習が行われるので, 
全部で $2\times 5=10$
回の学習が行われることになる. 

\item 上記の出力例の前半は,
 学習アルゴリズムに関する乱数の種 (\verb|ANN_seed|) および
 交差検定の分割に関する乱数の種 (\verb|split_seed|) をいずれも1としたときの学習過程を示している. 
 学習アルゴリズムの反復回数を 10,000 と定めたが, 
 適当な回数が済んだ時点でのニューラルネットワークの
 決定係数の値 (訓練集合, 試験集合の双方) および
 学習が開始してからの経過時間が示されている.  

\item プログラムの最後に, 選択されたニューラルネットワークの性能が出力される. 
\begin{itemize}
\item 複数回の交差検定を通じて, 決定係数の最良値 (すなわち最大値) は 0.859528 である.
\item 当該交差検定では五回の学習を行なったはずだが, 
そのうち試験集合に対する決定係数が最も良かったニューラルネットワークが選択される. 
そのニューラルネットワークの訓練集合に対する決定係数の値は 0.962288, 
試験集合に対する決定集合の値は 0.884223 である. 
\end{itemize}

\item 選択されたニューラルネットワークにおける枝重みが\verb|output_weights.txt|，
ノードのバイアスが\verb|output_biases.txt|に出力される．
繰り返すが, この二つのファイルは Module 3 の実行に必要である. 
\end{itemize}


\subsubsection{枝の重み}
\verb|2L_ANN.py|が出力する枝重みファイルの書式について説明する．

簡単のため，\figref{sample}に示したニューラルネットワークが学習されたとする．
このニューラルネットワークの枝重みは以下のようにファイルに出力される．

\begin{oframed}
{\small
\begin{verbatim}
3 2 1
1.1 2.3
-0.4 0.8
1.8 3.1
2.6
1.5
\end{verbatim}
}
\end{oframed}
\begin{itemize}
\item 最初の行はニューラルネットワークの構造，つまり入力層のノード数，各隠れ層のノード数，最後に出力層のノード数である．
\item 2行目以降は枝重みの値である．各行は1つのノードから出る枝重みの値を示す．
\end{itemize}


\subsubsection{ノードのバイアス}
同じく，\verb|2L_ANN.py|が出力するノードの
バイアスに関するファイルの書式について説明する．

やはり簡単のため，\figref{sample}に示したニューラルネットワークが学習されたとする．
このニューラルネットワークのノードのバイアスは以下のようにファイルに出力される．

\begin{oframed}
{\small
\begin{verbatim}
0.7
-1.2
2.1
\end{verbatim}
}
\end{oframed}
1行につき1つのノードのバイアスの値が示されている．
入力層のノードにはバイアスの値がないことに注意せよ．

\invis{
\begin{thebibliography}{9}
\bibitem{pubchem} HSDB in PubChem \url{https://pubchem.ncbi.nlm.nih.gov} (2021年2月1日 アクセス確認)
\end{thebibliography}
}

\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

